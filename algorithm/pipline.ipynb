{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вы можете объединить все части кода в единый алгоритм:\n",
    "\n",
    "1. Тензорное модальное разложение (TBMD):\n",
    "* Выполнить Tucker-разложение тензора 𝑋 для получения тензора 𝐴.\n",
    "\n",
    "2. Оптимальное размещение сенсоров:\n",
    "* Применить тензорное QR-разложение к 𝐴 для получения матрицы 𝑃.\n",
    "\n",
    "3. Формирование измерений:\n",
    "* Сформировать измерения 𝑌 с использованием 𝑃 и 𝑋.\n",
    "\n",
    "4. Восстановление вектора весов 𝑥:\n",
    "* Применить тензорное компрессивное измерение для восстановления 𝑥.\n",
    "\n",
    "5. Восстановление поля 𝑋:\n",
    "* Использовать 𝑥 и 𝐴 для восстановления 𝑋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorly\n",
      "  Downloading tensorly-0.8.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting numpy (from tensorly)\n",
      "  Using cached numpy-2.1.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scipy (from tensorly)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading tensorly-0.8.1-py3-none-any.whl (229 kB)\n",
      "Using cached torch-2.5.1-cp312-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached numpy-2.1.3-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "Using cached setuptools-75.3.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, setuptools, numpy, networkx, MarkupSafe, fsspec, filelock, scipy, jinja2, torch, tensorly\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.10.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.3 scipy-1.14.1 setuptools-75.3.0 sympy-1.13.1 tensorly-0.8.1 torch-2.5.1 typing-extensions-4.12.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U tensorly torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly import tenalg\n",
    "from tensorly.tenalg import mode_dot\n",
    "from typing import Set, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "tl.check_random_state(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры\n",
    "I, J, K = 5, 5, 5\n",
    "D = 3  # Количество наборов данных\n",
    "\n",
    "\n",
    "# Генерируем D тензоров данных\n",
    "X_tensor = np.random.rand(I, J, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying TBMD to each tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем тензорное модальное разложение (TBMD), в данном случае Tucker разложение, к каждому тензору, получая модальные тензоры 𝑀1, 𝑀2, …, 𝑀𝐷."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-5\n",
    "ranks = [min(I, J, K) for _ in range(3)]\n",
    "\n",
    "G_hat, factors = tucker(X_tensor, rank=ranks, tol=epsilon, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of the joint modal tensor 𝐴\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стекуем модальные тензоры 𝑀1, 𝑀2, …, 𝑀𝐷 по третьему измерению (или создаем объединенный тензор), получая тензор 𝐴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предполагаем, что вы уже извлекли A_hat и B_hat из factors\n",
    "A_hat, B_hat, C_hat = factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_list = []\n",
    "for n in range(G_hat.shape[2]):\n",
    "    G_slice = G_hat[:, :, n]  # Срез ядра по третьему измерению\n",
    "    M_n = A_hat @ G_slice @ B_hat.T  # Матрица размера (I x J)\n",
    "    M_list.append(M_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем модальные матрицы в тензор A\n",
    "A_tensor = np.stack(M_list, axis=-1)  # Размерность будет (I, J, R), где R — число мод (ранг по третьему измерению)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Tensor QR Decomposition for Optimal Sensor Placement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам нужно применить тензорное QR-разложение к тензору 𝐴 для получения матрицы перестановок 𝑃, которая будет использоваться для оптимального размещения сенсоров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_based_tube_fiber_pivot_qr_factorization(R: tl.tensor, N: int) -> Tuple[tl.tensor, tl.tensor, tl.tensor]:\n",
    "    \"\"\"\n",
    "    Implements the Tensor-based Tube Fiber-pivot QR Factorization.\n",
    "\n",
    "    Parameters:\n",
    "    - R: Input 3D tensor of shape (n1 x n2 x m), where n1 and n2 are dimensions of the matrix,\n",
    "         and m is the size of each tube (depth).\n",
    "    - N: Number of iterations for the factorization.\n",
    "    - A: Set of already used indices (to avoid repetition in the pivot).\n",
    "    - P: Output permutation matrix (n1 x n2) for selecting sensors or fibers.\n",
    "    - Q: Orthogonal matrix to be updated (m x m).\n",
    "    - M: Matrix to store the ℓ1-norms (n1 x n2) of the tubes from tensor R.\n",
    "\n",
    "    Returns:\n",
    "    - P: Updated permutation matrix with selected sensor placements.\n",
    "    - Q: Updated orthogonal matrix after each iteration.\n",
    "    - R: Updated tensor after applying Householder transformations.\n",
    "    \"\"\"\n",
    "\n",
    "    n1, n2, m = R.shape\n",
    "    P = np.zeros((n1, n2))  # Размерности матрицы P\n",
    "    Q = np.eye(m)  # Предполагаем, что третья размерность соответствует времени или другому измерению\n",
    "    M = np.zeros((n1, n2))\n",
    "    A_set = set()\n",
    "\n",
    "\n",
    "    for d in range(N):\n",
    "        # Compute tubular ℓ1-norms and fill matrix M\n",
    "        for i in range(n1):\n",
    "            for j in range(n2):\n",
    "                tube = R[i, j, :]\n",
    "                M[i, j] = tl.norm(tube, 1)  # Using ℓ1-norm\n",
    "\n",
    "        # Find the maximum element in M that has not been used\n",
    "        while True:\n",
    "            max_index = tl.argmax(M)\n",
    "            max_index = int(max_index)\n",
    "            x, y = divmod(max_index, n2)\n",
    "            if (x, y) not in A_set:\n",
    "                break\n",
    "            else:\n",
    "                M[x, y] = 0  # Zero out the element to avoid reusing it\n",
    "\n",
    "        A_set.add((x, y))\n",
    "        P[x, y] = 1  # Set the corresponding element in P to 1\n",
    "\n",
    "        # Extract vector t from tensor R\n",
    "        t = R[x, y, d:]\n",
    "\n",
    "        # Compute sigma and vector u\n",
    "        sigma = tl.norm(t, 2)\n",
    "        if sigma == 0:\n",
    "            u = tl.zeros_like(t)\n",
    "        else:\n",
    "            e_d = tl.zeros_like(t)\n",
    "            e_d[0] = 1  # Position 0 corresponds to position d in Python\n",
    "            t1 = t[0]\n",
    "            sign_t1 = tl.sign(t1) if t1 != 0 else 1\n",
    "            numerator = t + sign_t1 * sigma * e_d\n",
    "            denominator = tl.sqrt(2 * sigma * (sigma + tl.abs(t1)))\n",
    "            u = numerator / denominator\n",
    "\n",
    "        # Update R for slice x, y, d:m\n",
    "        R_slice = R[x, y, d:]\n",
    "        R[x, y, d:] = R_slice - 2 * u * tl.dot(u, R_slice)\n",
    "\n",
    "        # Update Q matrix\n",
    "        u_Q = u.reshape(-1, 1)  # Reshape u to (m - d, 1)\n",
    "        Q_d = Q[:, d:]  # Get submatrix of Q from column d onwards\n",
    "        Q[:, d:] = Q_d - 2 * Q_d @ (u_Q @ u_Q.T)  # Update Q\n",
    "\n",
    "    # Return the updated P, Q, and R matrices\n",
    "    return P, Q, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tensor_based_tube_fiber_pivot_qr_factorization(R, N):\n",
    "#     n1, n2, m = R.shape\n",
    "#     P = np.zeros((n1, n2))\n",
    "#     Q = np.eye(m)\n",
    "#     M = np.zeros((n1, n2))\n",
    "#     A_set = set()\n",
    "    \n",
    "#     for d in range(N):\n",
    "#         # Вычисляем ℓ1-нормы трубок\n",
    "#         for i in range(n1):\n",
    "#             for j in range(n2):\n",
    "#                 tube = R[i, j, d:]\n",
    "#                 M[i, j] = np.linalg.norm(tube, 1)\n",
    "                \n",
    "#         # Находим максимальную норму\n",
    "#         while True:\n",
    "#             max_index = np.argmax(M)\n",
    "#             x, y = divmod(max_index, n2)\n",
    "#             if (x, y) not in A_set:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 M[x, y] = 0\n",
    "        \n",
    "#         A_set.add((x, y))\n",
    "#         P[x, y] = 1\n",
    "        \n",
    "#         # Обновляем R и Q\n",
    "#         t = R[x, y, d:]\n",
    "#         sigma = np.linalg.norm(t)\n",
    "#         if sigma == 0:\n",
    "#             u = np.zeros_like(t)\n",
    "#         else:\n",
    "#             e_d = np.zeros_like(t)\n",
    "#             e_d[0] = 1\n",
    "#             sign_t1 = np.sign(t[0]) if t[0] != 0 else 1\n",
    "#             u = (t + sign_t1 * sigma * e_d) / np.sqrt(2 * sigma * (sigma + abs(t[0])))\n",
    "        \n",
    "#         # Обновляем R\n",
    "#         R_slice = R[:, :, d:]\n",
    "#         R[:, :, d:] = R_slice - 2 * np.tensordot(u, np.tensordot(u, R_slice, axes=([0], [2])), axes=([0], [0]))\n",
    "        \n",
    "#         # Обновляем Q\n",
    "#         u_Q = u.reshape(-1, 1)\n",
    "#         Q_d = Q[:, d:]\n",
    "#         Q[:, d:] = Q_d - 2 * Q_d @ (u_Q @ u_Q.T)\n",
    "        \n",
    "#     return P, Q, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры для QR-разложения\n",
    "N = 5  # Задайте количество сенсоров\n",
    "\n",
    "# Применяем функцию (не забудьте адаптировать функцию под ваши данные)\n",
    "P, Q, R = tensor_based_tube_fiber_pivot_qr_factorization(A_tensor, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Norm of (Q^T Q - I): 7.805874596144724e-16\n"
     ]
    }
   ],
   "source": [
    "Q_T_Q = tl.dot(Q.T, Q)\n",
    "identity = tl.tensor(np.eye(A_tensor.shape[2]), dtype=tl.float32)\n",
    "difference = tl.norm(Q_T_Q - identity)\n",
    "\n",
    "\n",
    "print(f\"\\nNorm of (Q^T Q - I): {difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formation of dimensions 𝑌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После получения матрицы 𝑃 вы можете сформировать матрицу измерений 𝑌 из исходного тензора 𝑋."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем индексы выбранных сенсоров\n",
    "sensor_indices = np.argwhere(P == 1)\n",
    "\n",
    "Y_list = []\n",
    "\n",
    "for idx in sensor_indices:\n",
    "    i, j = idx\n",
    "    # Извлекаем временной ряд данных для позиции сенсора (i, j)\n",
    "    time_series = X_tensor[i, j, :]  # Размерность (K,)\n",
    "    Y_list.append(time_series)\n",
    "\n",
    "# Преобразуем список в numpy-массив\n",
    "Y = np.array(Y_list)  # Размерность (N, K), где N — количество сенсоров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor compression measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно решить оптимизационную задачу для восстановления вектора весов 𝑥, используя измерения 𝑌 и тензор 𝐴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_based_compressive_sensing(\n",
    "    A: Union[np.ndarray, tl.tensor],\n",
    "    P: Union[np.ndarray, tl.tensor],\n",
    "    Y: Union[np.ndarray, tl.tensor],\n",
    "    max_iter: int,\n",
    "    epsilon: float,\n",
    "    lambd: float,\n",
    "    delta_0: float,\n",
    "    delta_max: float\n",
    ") -> tl.tensor:\n",
    "    \"\"\"\n",
    "    Implements the Tensor-based Compressive Sensing Algorithm (Algorithm 3).\n",
    "    \n",
    "    Parameters:\n",
    "    - A: Input tensor of shape (I x J x W) (numpy array or Tensorly tensor)\n",
    "    - P: Permutation matrix or sensor selection matrix (should be compatible for mode-0 multiplication with A)\n",
    "         (numpy array or Tensorly tensor)\n",
    "    - Y: Observed data tensor (after sensor placement) (numpy array or Tensorly tensor)\n",
    "    - max_iter: Maximum number of iterations (int)\n",
    "    - epsilon: Small positive scalar for shrinkage thresholding (float)\n",
    "    - lambd: Regularization parameter (float)\n",
    "    - delta_0: Initial value for the Lagrange penalty term (float)\n",
    "    - delta_max: Maximum value for delta (float)\n",
    "\n",
    "    Returns:\n",
    "    - x_hat: Recovered sparse code vector of shape (W x 1) (Tensorly tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure A, P, Y are tensors\n",
    "    A = tl.tensor(A, dtype=tl.float32)\n",
    "    P = tl.tensor(P, dtype=tl.float32)\n",
    "    Y = tl.tensor(Y, dtype=tl.float32)\n",
    "\n",
    "    # Get dimensions\n",
    "    I, J, W = A.shape\n",
    "\n",
    "    # Initialize variables\n",
    "    x_n = tl.zeros((W, 1), dtype=tl.float32)\n",
    "    d_n = tl.zeros((W, 1), dtype=tl.float32)\n",
    "    p_n = tl.zeros((W, 1), dtype=tl.float32)\n",
    "    delta_n = delta_0\n",
    "\n",
    "    # Preprocess A: A = P x1 A (since P is (N x I), we use mode-0 multiplication)\n",
    "    A = mode_dot(A, P, mode=0)  # A now has shape (N, J, W)\n",
    "\n",
    "    # Unfold A along mode-2 (mode-3 in MATLAB notation)\n",
    "    A_unfold = tl.unfold(A, mode=2)  # Shape: (W, N * J)\n",
    "\n",
    "    # Compute A_T_A and A_Y\n",
    "    A_T_A = A_unfold @ A_unfold.T  # Shape: (W, W)\n",
    "\n",
    "    # Reshape Y to match the dimensions\n",
    "    Y_vector = Y.reshape(-1, 1)  # Shape: (N * J, 1)\n",
    "\n",
    "    # Compute A_Y\n",
    "    A_Y = A_unfold @ Y_vector  # Shape: (W, 1)\n",
    "\n",
    "    # Start iterations\n",
    "    for n in range(1, max_iter + 1):\n",
    "        # Update x_n\n",
    "        # Solve: (A_T_A + delta_n * I) * x_n = A_Y + delta_n * (d_n - p_n)\n",
    "        left_matrix = A_T_A + delta_n * np.eye(W)\n",
    "        right_vector = A_Y + delta_n * (d_n - p_n)\n",
    "        x_n = np.linalg.solve(left_matrix, right_vector)\n",
    "\n",
    "        # Compute x_hat\n",
    "        x_hat = lambd * x_n + (1 - lambd) * d_n\n",
    "\n",
    "        # Update d_n using iterative shrinkage-thresholding\n",
    "        threshold = epsilon / delta_n\n",
    "        temp = x_hat + p_n\n",
    "        d_n = np.maximum(0, temp - threshold) - np.maximum(0, -temp - threshold)\n",
    "\n",
    "        # Update p_n\n",
    "        p_n = p_n + x_hat - d_n\n",
    "\n",
    "        # Update delta_n\n",
    "        delta_n = min(delta_n, delta_max)\n",
    "\n",
    "    return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры для компрессивного измерения\n",
    "max_iter = 100\n",
    "epsilon_cs = 1e-5  # Используем другое имя для epsilon, чтобы не путать с предыдущим\n",
    "lambda_ = 0.1\n",
    "delta_0 = 0.01\n",
    "delta_max = 1.0\n",
    "\n",
    "A_cs = tl.tensor(A_tensor, dtype=tl.float32)\n",
    "Y_cs = tl.tensor(Y, dtype=tl.float32)\n",
    "P_cs = tl.tensor(P, dtype=tl.float32)\n",
    "\n",
    "x_hat = tensor_based_compressive_sensing(\n",
    "    A_cs, P_cs, Y_cs, max_iter, epsilon_cs, lambda_, delta_0, delta_max\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field restoration 𝑋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя полученный вектор весов 𝑥, мы можем восстановить поле 𝑋."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Восстанавливаем тензорное поле\n",
    "# x_hat должен быть размерности (R,)\n",
    "X_reconstructed = tl.tenalg.mode_dot(A_tensor, x_hat.squeeze(), mode=2)  # Применяем x_hat по третьему измерению\n",
    "\n",
    "# X_reconstructed будет тензором размерности (I, J)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
