{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ —á–∞—Å—Ç–∏ –∫–æ–¥–∞ –≤ –µ–¥–∏–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º:\n",
    "\n",
    "1. –¢–µ–Ω–∑–æ—Ä–Ω–æ–µ –º–æ–¥–∞–ª—å–Ω–æ–µ —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ (TBMD):\n",
    "* –í—ã–ø–æ–ª–Ω–∏—Ç—å Tucker-—Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–∞ ùëã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–Ω–∑–æ—Ä–∞ ùê¥.\n",
    "\n",
    "2. –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏–µ —Å–µ–Ω—Å–æ—Ä–æ–≤:\n",
    "* –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–µ–Ω–∑–æ—Ä–Ω–æ–µ QR-—Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ –∫ ùê¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã ùëÉ.\n",
    "\n",
    "3. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–º–µ—Ä–µ–Ω–∏–π:\n",
    "* –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏—è ùëå —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ùëÉ –∏ ùëã.\n",
    "\n",
    "4. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∞ –≤–µ—Å–æ–≤ ùë•:\n",
    "* –ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–µ–Ω–∑–æ—Ä–Ω–æ–µ –∫–æ–º–ø—Ä–µ—Å—Å–∏–≤–Ω–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è ùë•.\n",
    "\n",
    "5. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ–ª—è ùëã:\n",
    "* –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ùë• –∏ ùê¥ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è ùëã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorly\n",
      "  Downloading tensorly-0.8.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.5.1-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting numpy (from tensorly)\n",
      "  Using cached numpy-2.1.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scipy (from tensorly)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Downloading tensorly-0.8.1-py3-none-any.whl (229 kB)\n",
      "Using cached torch-2.5.1-cp312-none-macosx_11_0_arm64.whl (63.9 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached numpy-2.1.3-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "Using cached setuptools-75.3.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, setuptools, numpy, networkx, MarkupSafe, fsspec, filelock, scipy, jinja2, torch, tensorly\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.16.1 fsspec-2024.10.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.3 scipy-1.14.1 setuptools-75.3.0 sympy-1.13.1 tensorly-0.8.1 torch-2.5.1 typing-extensions-4.12.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U tensorly torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly import tenalg\n",
    "from tensorly.tenalg import mode_dot\n",
    "from typing import Set, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "tl.check_random_state(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "I, J, K = 5, 5, 5\n",
    "D = 3  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º D —Ç–µ–Ω–∑–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "X_tensor = np.random.rand(I, J, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying TBMD to each tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ–Ω–∑–æ—Ä–Ω–æ–µ –º–æ–¥–∞–ª—å–Ω–æ–µ —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ (TBMD), –≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ Tucker —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ, –∫ –∫–∞–∂–¥–æ–º—É —Ç–µ–Ω–∑–æ—Ä—É, –ø–æ–ª—É—á–∞—è –º–æ–¥–∞–ª—å–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã ùëÄ1, ùëÄ2, ‚Ä¶, ùëÄùê∑."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-5\n",
    "ranks = [min(I, J, K) for _ in range(3)]\n",
    "\n",
    "G_hat, factors = tucker(X_tensor, rank=ranks, tol=epsilon, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction of the joint modal tensor ùê¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°—Ç–µ–∫—É–µ–º –º–æ–¥–∞–ª—å–Ω—ã–µ —Ç–µ–Ω–∑–æ—Ä—ã ùëÄ1, ùëÄ2, ‚Ä¶, ùëÄùê∑ –ø–æ —Ç—Ä–µ—Ç—å–µ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é (–∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä), –ø–æ–ª—É—á–∞—è —Ç–µ–Ω–∑–æ—Ä ùê¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –≤—ã —É–∂–µ –∏–∑–≤–ª–µ–∫–ª–∏ A_hat –∏ B_hat –∏–∑ factors\n",
    "A_hat, B_hat, C_hat = factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_list = []\n",
    "for n in range(G_hat.shape[2]):\n",
    "    G_slice = G_hat[:, :, n]  # –°—Ä–µ–∑ —è–¥—Ä–∞ –ø–æ —Ç—Ä–µ—Ç—å–µ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é\n",
    "    M_n = A_hat @ G_slice @ B_hat.T  # –ú–∞—Ç—Ä–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–∞ (I x J)\n",
    "    M_list.append(M_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–±–∏—Ä–∞–µ–º –º–æ–¥–∞–ª—å–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã –≤ —Ç–µ–Ω–∑–æ—Ä A\n",
    "A_tensor = np.stack(M_list, axis=-1)  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±—É–¥–µ—Ç (I, J, R), –≥–¥–µ R ‚Äî —á–∏—Å–ª–æ –º–æ–¥ (—Ä–∞–Ω–≥ –ø–æ —Ç—Ä–µ—Ç—å–µ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Tensor QR Decomposition for Optimal Sensor Placement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω–∞–º –Ω—É–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ç–µ–Ω–∑–æ—Ä–Ω–æ–µ QR-—Ä–∞–∑–ª–æ–∂–µ–Ω–∏–µ –∫ —Ç–µ–Ω–∑–æ—Ä—É ùê¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ–∫ ùëÉ, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è —Å–µ–Ω—Å–æ—Ä–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_based_tube_fiber_pivot_qr_factorization(R: tl.tensor, N: int) -> Tuple[tl.tensor, tl.tensor, tl.tensor]:\n",
    "    \"\"\"\n",
    "    Implements the Tensor-based Tube Fiber-pivot QR Factorization.\n",
    "\n",
    "    Parameters:\n",
    "    - R: Input 3D tensor of shape (n1 x n2 x m), where n1 and n2 are dimensions of the matrix,\n",
    "         and m is the size of each tube (depth).\n",
    "    - N: Number of iterations for the factorization.\n",
    "    - A: Set of already used indices (to avoid repetition in the pivot).\n",
    "    - P: Output permutation matrix (n1 x n2) for selecting sensors or fibers.\n",
    "    - Q: Orthogonal matrix to be updated (m x m).\n",
    "    - M: Matrix to store the ‚Ñì1-norms (n1 x n2) of the tubes from tensor R.\n",
    "\n",
    "    Returns:\n",
    "    - P: Updated permutation matrix with selected sensor placements.\n",
    "    - Q: Updated orthogonal matrix after each iteration.\n",
    "    - R: Updated tensor after applying Householder transformations.\n",
    "    \"\"\"\n",
    "\n",
    "    n1, n2, m = R.shape\n",
    "    P = np.zeros((n1, n2))  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –º–∞—Ç—Ä–∏—Ü—ã P\n",
    "    Q = np.eye(m)  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ç—Ä–µ—Ç—å—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –∏–ª–∏ –¥—Ä—É–≥–æ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é\n",
    "    M = np.zeros((n1, n2))\n",
    "    A_set = set()\n",
    "\n",
    "\n",
    "    for d in range(N):\n",
    "        # Compute tubular ‚Ñì1-norms and fill matrix M\n",
    "        for i in range(n1):\n",
    "            for j in range(n2):\n",
    "                tube = R[i, j, :]\n",
    "                M[i, j] = tl.norm(tube, 1)  # Using ‚Ñì1-norm\n",
    "\n",
    "        # Find the maximum element in M that has not been used\n",
    "        while True:\n",
    "            max_index = tl.argmax(M)\n",
    "            max_index = int(max_index)\n",
    "            x, y = divmod(max_index, n2)\n",
    "            if (x, y) not in A_set:\n",
    "                break\n",
    "            else:\n",
    "                M[x, y] = 0  # Zero out the element to avoid reusing it\n",
    "\n",
    "        A_set.add((x, y))\n",
    "        P[x, y] = 1  # Set the corresponding element in P to 1\n",
    "\n",
    "        # Extract vector t from tensor R\n",
    "        t = R[x, y, d:]\n",
    "\n",
    "        # Compute sigma and vector u\n",
    "        sigma = tl.norm(t, 2)\n",
    "        if sigma == 0:\n",
    "            u = tl.zeros_like(t)\n",
    "        else:\n",
    "            e_d = tl.zeros_like(t)\n",
    "            e_d[0] = 1  # Position 0 corresponds to position d in Python\n",
    "            t1 = t[0]\n",
    "            sign_t1 = tl.sign(t1) if t1 != 0 else 1\n",
    "            numerator = t + sign_t1 * sigma * e_d\n",
    "            denominator = tl.sqrt(2 * sigma * (sigma + tl.abs(t1)))\n",
    "            u = numerator / denominator\n",
    "\n",
    "        # Update R for slice x, y, d:m\n",
    "        R_slice = R[x, y, d:]\n",
    "        R[x, y, d:] = R_slice - 2 * u * tl.dot(u, R_slice)\n",
    "\n",
    "        # Update Q matrix\n",
    "        u_Q = u.reshape(-1, 1)  # Reshape u to (m - d, 1)\n",
    "        Q_d = Q[:, d:]  # Get submatrix of Q from column d onwards\n",
    "        Q[:, d:] = Q_d - 2 * Q_d @ (u_Q @ u_Q.T)  # Update Q\n",
    "\n",
    "    # Return the updated P, Q, and R matrices\n",
    "    return P, Q, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tensor_based_tube_fiber_pivot_qr_factorization(R, N):\n",
    "#     n1, n2, m = R.shape\n",
    "#     P = np.zeros((n1, n2))\n",
    "#     Q = np.eye(m)\n",
    "#     M = np.zeros((n1, n2))\n",
    "#     A_set = set()\n",
    "    \n",
    "#     for d in range(N):\n",
    "#         # –í—ã—á–∏—Å–ª—è–µ–º ‚Ñì1-–Ω–æ—Ä–º—ã —Ç—Ä—É–±–æ–∫\n",
    "#         for i in range(n1):\n",
    "#             for j in range(n2):\n",
    "#                 tube = R[i, j, d:]\n",
    "#                 M[i, j] = np.linalg.norm(tube, 1)\n",
    "                \n",
    "#         # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –Ω–æ—Ä–º—É\n",
    "#         while True:\n",
    "#             max_index = np.argmax(M)\n",
    "#             x, y = divmod(max_index, n2)\n",
    "#             if (x, y) not in A_set:\n",
    "#                 break\n",
    "#             else:\n",
    "#                 M[x, y] = 0\n",
    "        \n",
    "#         A_set.add((x, y))\n",
    "#         P[x, y] = 1\n",
    "        \n",
    "#         # –û–±–Ω–æ–≤–ª—è–µ–º R –∏ Q\n",
    "#         t = R[x, y, d:]\n",
    "#         sigma = np.linalg.norm(t)\n",
    "#         if sigma == 0:\n",
    "#             u = np.zeros_like(t)\n",
    "#         else:\n",
    "#             e_d = np.zeros_like(t)\n",
    "#             e_d[0] = 1\n",
    "#             sign_t1 = np.sign(t[0]) if t[0] != 0 else 1\n",
    "#             u = (t + sign_t1 * sigma * e_d) / np.sqrt(2 * sigma * (sigma + abs(t[0])))\n",
    "        \n",
    "#         # –û–±–Ω–æ–≤–ª—è–µ–º R\n",
    "#         R_slice = R[:, :, d:]\n",
    "#         R[:, :, d:] = R_slice - 2 * np.tensordot(u, np.tensordot(u, R_slice, axes=([0], [2])), axes=([0], [0]))\n",
    "        \n",
    "#         # –û–±–Ω–æ–≤–ª—è–µ–º Q\n",
    "#         u_Q = u.reshape(-1, 1)\n",
    "#         Q_d = Q[:, d:]\n",
    "#         Q[:, d:] = Q_d - 2 * Q_d @ (u_Q @ u_Q.T)\n",
    "        \n",
    "#     return P, Q, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è QR-—Ä–∞–∑–ª–æ–∂–µ–Ω–∏—è\n",
    "N = 5  # –ó–∞–¥–∞–π—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–Ω—Å–æ—Ä–æ–≤\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é (–Ω–µ –∑–∞–±—É–¥—å—Ç–µ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø–æ–¥ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ)\n",
    "P, Q, R = tensor_based_tube_fiber_pivot_qr_factorization(A_tensor, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Norm of (Q^T Q - I): 7.805874596144724e-16\n"
     ]
    }
   ],
   "source": [
    "Q_T_Q = tl.dot(Q.T, Q)\n",
    "identity = tl.tensor(np.eye(A_tensor.shape[2]), dtype=tl.float32)\n",
    "difference = tl.norm(Q_T_Q - identity)\n",
    "\n",
    "\n",
    "print(f\"\\nNorm of (Q^T Q - I): {difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formation of dimensions ùëå\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –º–∞—Ç—Ä–∏—Ü—ã ùëÉ –≤—ã –º–æ–∂–µ—Ç–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –º–∞—Ç—Ä–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏–π ùëå –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–Ω–∑–æ—Ä–∞ ùëã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å–µ–Ω—Å–æ—Ä–æ–≤\n",
    "sensor_indices = np.argwhere(P == 1)\n",
    "\n",
    "Y_list = []\n",
    "\n",
    "for idx in sensor_indices:\n",
    "    i, j = idx\n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∑–∏—Ü–∏–∏ —Å–µ–Ω—Å–æ—Ä–∞ (i, j)\n",
    "    time_series = X_tensor[i, j, :]  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (K,)\n",
    "    Y_list.append(time_series)\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–æ–∫ –≤ numpy-–º–∞—Å—Å–∏–≤\n",
    "Y = np.array(Y_list)  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (N, K), –≥–¥–µ N ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–Ω—Å–æ—Ä–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor compression measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –Ω—É–∂–Ω–æ —Ä–µ—à–∏—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω—É—é –∑–∞–¥–∞—á—É –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–∞ –≤–µ—Å–æ–≤ ùë•, –∏—Å–ø–æ–ª—å–∑—É—è –∏–∑–º–µ—Ä–µ–Ω–∏—è ùëå –∏ —Ç–µ–Ω–∑–æ—Ä ùê¥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_based_compressive_sensing(\n",
    "    A: Union[np.ndarray, tl.tensor],\n",
    "    P: Union[np.ndarray, tl.tensor],\n",
    "    Y: Union[np.ndarray, tl.tensor],\n",
    "    max_iter: int,\n",
    "    epsilon: float,\n",
    "    lambd: float,\n",
    "    delta_0: float,\n",
    "    delta_max: float\n",
    ") -> tl.tensor:\n",
    "    \"\"\"\n",
    "    Implements the Tensor-based Compressive Sensing Algorithm (Algorithm 3).\n",
    "    \n",
    "    Parameters:\n",
    "    - A: Input tensor of shape (I x J x W) (numpy array or Tensorly tensor)\n",
    "    - P: Permutation matrix or sensor selection matrix (should be compatible for mode-0 multiplication with A)\n",
    "         (numpy array or Tensorly tensor)\n",
    "    - Y: Observed data tensor (after sensor placement) (numpy array or Tensorly tensor)\n",
    "    - max_iter: Maximum number of iterations (int)\n",
    "    - epsilon: Small positive scalar for shrinkage thresholding (float)\n",
    "    - lambd: Regularization parameter (float)\n",
    "    - delta_0: Initial value for the Lagrange penalty term (float)\n",
    "    - delta_max: Maximum value for delta (float)\n",
    "\n",
    "    Returns:\n",
    "    - x_hat: Recovered sparse code vector of shape (W x 1) (Tensorly tensor)\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure A, P, Y are tensors\n",
    "    A = tl.tensor(A, dtype=tl.float32)\n",
    "    P = tl.tensor(P, dtype=tl.float32)\n",
    "    Y = tl.tensor(Y, dtype=tl.float32)\n",
    "\n",
    "    # Get dimensions\n",
    "    I, J, W = A.shape\n",
    "\n",
    "    # Initialize variables\n",
    "    x_n = tl.zeros((W, 1), dtype=tl.float32)\n",
    "    d_n = tl.zeros((W, 1), dtype=tl.float32)\n",
    "    p_n = tl.zeros((W, 1), dtype=tl.float32)\n",
    "    delta_n = delta_0\n",
    "\n",
    "    # Preprocess A: A = P x1 A (since P is (N x I), we use mode-0 multiplication)\n",
    "    A = mode_dot(A, P, mode=0)  # A now has shape (N, J, W)\n",
    "\n",
    "    # Unfold A along mode-2 (mode-3 in MATLAB notation)\n",
    "    A_unfold = tl.unfold(A, mode=2)  # Shape: (W, N * J)\n",
    "\n",
    "    # Compute A_T_A and A_Y\n",
    "    A_T_A = A_unfold @ A_unfold.T  # Shape: (W, W)\n",
    "\n",
    "    # Reshape Y to match the dimensions\n",
    "    Y_vector = Y.reshape(-1, 1)  # Shape: (N * J, 1)\n",
    "\n",
    "    # Compute A_Y\n",
    "    A_Y = A_unfold @ Y_vector  # Shape: (W, 1)\n",
    "\n",
    "    # Start iterations\n",
    "    for n in range(1, max_iter + 1):\n",
    "        # Update x_n\n",
    "        # Solve: (A_T_A + delta_n * I) * x_n = A_Y + delta_n * (d_n - p_n)\n",
    "        left_matrix = A_T_A + delta_n * np.eye(W)\n",
    "        right_vector = A_Y + delta_n * (d_n - p_n)\n",
    "        x_n = np.linalg.solve(left_matrix, right_vector)\n",
    "\n",
    "        # Compute x_hat\n",
    "        x_hat = lambd * x_n + (1 - lambd) * d_n\n",
    "\n",
    "        # Update d_n using iterative shrinkage-thresholding\n",
    "        threshold = epsilon / delta_n\n",
    "        temp = x_hat + p_n\n",
    "        d_n = np.maximum(0, temp - threshold) - np.maximum(0, -temp - threshold)\n",
    "\n",
    "        # Update p_n\n",
    "        p_n = p_n + x_hat - d_n\n",
    "\n",
    "        # Update delta_n\n",
    "        delta_n = min(delta_n, delta_max)\n",
    "\n",
    "    return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–æ–º–ø—Ä–µ—Å—Å–∏–≤–Ω–æ–≥–æ –∏–∑–º–µ—Ä–µ–Ω–∏—è\n",
    "max_iter = 100\n",
    "epsilon_cs = 1e-5  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥—Ä—É–≥–æ–µ –∏–º—è –¥–ª—è epsilon, —á—Ç–æ–±—ã –Ω–µ –ø—É—Ç–∞—Ç—å —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º\n",
    "lambda_ = 0.1\n",
    "delta_0 = 0.01\n",
    "delta_max = 1.0\n",
    "\n",
    "A_cs = tl.tensor(A_tensor, dtype=tl.float32)\n",
    "Y_cs = tl.tensor(Y, dtype=tl.float32)\n",
    "P_cs = tl.tensor(P, dtype=tl.float32)\n",
    "\n",
    "x_hat = tensor_based_compressive_sensing(\n",
    "    A_cs, P_cs, Y_cs, max_iter, epsilon_cs, lambda_, delta_0, delta_max\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field restoration ùëã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å–ø–æ–ª—å–∑—É—è –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –≤–µ—Å–æ–≤ ùë•, –º—ã –º–æ–∂–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–ª–µ ùëã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–Ω–∑–æ—Ä–Ω–æ–µ –ø–æ–ª–µ\n",
    "# x_hat –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (R,)\n",
    "X_reconstructed = tl.tenalg.mode_dot(A_tensor, x_hat.squeeze(), mode=2)  # –ü—Ä–∏–º–µ–Ω—è–µ–º x_hat –ø–æ —Ç—Ä–µ—Ç—å–µ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é\n",
    "\n",
    "# X_reconstructed –±—É–¥–µ—Ç —Ç–µ–Ω–∑–æ—Ä–æ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (I, J)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
