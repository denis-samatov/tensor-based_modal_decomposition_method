# Тензорное Компрессивное Измерение

## Введение

**Компрессивное измерение** (Compressive Sensing, CS) — это теория и методология, позволяющие восстанавливать сигналы и изображения из меньшего числа измерений, чем требуется по классической теории выборки Найквиста-Шеннона. CS основывается на предположении, что сигнал является разреженным или может быть разреженно представлен в некотором базисе.

В области динамических систем компрессивное измерение широко используется для восстановления глобальной информации о системе на основе оптимального разреженного размещения датчиков [48, 49].

### Проблема с классическими методами

Классические методы компрессивного измерения основаны на матричном представлении данных. Однако в нашей работе мы имеем дело с тензорами (многомерными массивами данных), что делает классические методы неприменимыми для нашей задачи восстановления поля на основе тензорных данных.

## Тензорное Компрессивное Измерение

В этой секции мы представляем метод тензорного компрессивного измерения для восстановления поля на основе тензорных данных.

### Постановка Задачи

Учитывая разреженность вектора \( \mathbf{x} \), точное решение уравнения (15) можно сформулировать как задачу минимизации \( \ell_0 \)-нормы:

\[
\min_{\mathbf{x}} \| \mathbf{x} \|_0 \quad \text{при условии} \quad \mathbf{Y} = \mathbf{P} \times_3 \mathcal{A} \times_{(3)} \mathbf{x} \tag{25}
\]

- \( \| \mathbf{x} \|_0 \) — \( \ell_0 \)-норма вектора \( \mathbf{x} \), то есть количество ненулевых элементов в \( \mathbf{x} \).
- \( \mathbf{Y} \) — измерения, полученные с разреженных датчиков.
- \( \mathbf{P} \times_3 \mathcal{A} \) — произведение оператора выбора датчиков на тензор словаря по третьему измерению.
- \( \mathcal{A} \times_{(3)} \mathbf{x} \) — восстановленное поле на основе вектора весов \( \mathbf{x} \).

### Свойство Ограниченной Изометрии (RIP)

Для гарантии точного восстановления разреженного вектора \( \mathbf{x} \) необходимо выполнение **Свойства Ограниченной Изометрии** (Restricted Isometry Property, RIP). Для некоторого порядка \( h \) RIP выражается следующим образом:

\[
(1 - \delta_h) \| \mathbf{x} \|_2^2 \leq \| \mathbf{P} \times_3 \mathcal{A} \times_{(3)} \mathbf{x} \|_2^2 \leq (1 + \delta_h) \| \mathbf{x} \|_2^2 \tag{26}
\]

- \( \delta_h \) — константа RIP, удовлетворяющая \( 0 < \delta_h < 1 \).
- \( \| \mathbf{x} \|_2 \) — евклидова норма вектора \( \mathbf{x} \).
- \( h = \| \mathbf{x} \|_0 \) — количество ненулевых элементов в \( \mathbf{x} \).

**Требования для выполнения RIP**:

- Для ортогонального тензора словаря размерности \( I \times J \times W \) необходимо, чтобы \( W \geq 4K \) или \( W \geq h \log_2 \left( \frac{I \times J}{h} \right) \).

При размещении \( N \) разреженных датчиков размерность задачи сокращается до \( N \times W \). Таким образом, RIP выполняется при \( W \geq h \log_2 \left( \frac{N}{h} \right) \), что позволяет использовать методы минимизации \( \ell_1 \)-нормы для точного восстановления поля.

### Минимизация \( \ell_1 \)-нормы

Учитывая выполнение RIP, задачу (25) можно переформулировать как задачу минимизации \( \ell_1 \)-нормы:

\[
\min_{\mathbf{x}} \| \mathbf{x} \|_1 \quad \text{при условии} \quad \mathbf{Y} = \mathbf{P} \times_3 \mathcal{A} \times_{(3)} \mathbf{x} \tag{27}
\]

- \( \| \mathbf{x} \|_1 \) — сумма абсолютных значений элементов вектора \( \mathbf{x} \).

### Добавление Регуляризации

Убирая жесткое условие, переходим к следующей задаче оптимизации:

\[
\min_{\mathbf{x}} \lambda \| \mathbf{x} \|_1 + \frac{1}{2} \| \mathbf{P} \times_3 \mathcal{A} \times_{(3)} \mathbf{x} - \mathbf{Y} \|_F^2 \tag{28}
\]

- \( \lambda \) — параметр регуляризации, контролирующий баланс между разреженностью решения и точностью соответствия измерениям.
- \( \| \cdot \|_F \) — норма Фробениуса.

### Решение Задачи с Помощью ADMM

Задача (28) является невыпуклой и недифференцируемой из-за присутствия \( \ell_1 \)-нормы, что затрудняет ее решение методами градиентного спуска.

Для решения этой задачи мы используем **Метод Попеременных Направлений Умножителей** (Alternating Direction Method of Multipliers, ADMM).

#### Преобразование Задачи

Вводим дополнительную переменную \( \mathbf{d} \) и переписываем задачу в следующем виде:

\[
\min_{\mathbf{x}} \frac{1}{2} \| \mathbf{P} \times_3 \mathcal{A} \times_{(3)} \mathbf{x} - \mathbf{Y} \|_F^2 + \lambda \| \mathbf{d} \|_1 \quad \text{при условии} \quad \mathbf{x} - \mathbf{d} = 0 \tag{29}
\]

#### Расширенный Лагранжиан

Используем метод множителей Лагранжа для снятия ограничения:

\[
L(\mathbf{x}, \mathbf{d}, \boldsymbol{\mu}) = \frac{1}{2} \| \mathbf{P} \times_3 \mathcal{A} \times_{(3)} \mathbf{x} - \mathbf{Y} \|_F^2 + \lambda \| \mathbf{d} \|_1 + \boldsymbol{\mu}^\top (\mathbf{x} - \mathbf{d}) + \frac{\delta}{2} \| \mathbf{x} - \mathbf{d} \|_2^2 \tag{30}
\]

- \( \boldsymbol{\mu} \) — вектор множителей Лагранжа.
- \( \delta > 0 \) — параметр штрафа.

Перепишем выражение для удобства:

\[
L(\mathbf{x}, \mathbf{d}, \mathbf{p}) = \frac{1}{2} \| \mathbf{P} \times_3 \mathcal{A} \times_{(3)} \mathbf{x} - \mathbf{Y} \|_F^2 + \lambda \| \mathbf{d} \|_1 + \frac{\delta}{2} \| \mathbf{x} - \mathbf{d} + \mathbf{p} \|_2^2 - \frac{\delta}{2} \| \mathbf{p} \|_2^2 \tag{31}
\]

- \( \mathbf{p} = \frac{\boldsymbol{\mu}}{\delta} \).

#### Алгоритм ADMM

Решение задачи достигается путем попеременного минимизирования по \( \mathbf{x} \), \( \mathbf{d} \) и обновления \( \mathbf{p} \):

1. **Обновление \( \mathbf{x} \)**:

   \[
   \mathbf{x}^{(n+1)} = \arg \min_{\mathbf{x}} \frac{1}{2} \| \mathbf{P} \times_3 \mathcal{A} \times_{(3)} \mathbf{x} - \mathbf{Y} \|_F^2 + \frac{\delta^{(n)}}{2} \| \mathbf{x} - \mathbf{d}^{(n)} + \mathbf{p}^{(n)} \|_2^2 \tag{32}
   \]

2. **Обновление \( \mathbf{d} \)**:

   \[
   \mathbf{d}^{(n+1)} = \arg \min_{\mathbf{d}} \lambda \| \mathbf{d} \|_1 + \frac{\delta^{(n)}}{2} \| \mathbf{x}^{(n+1)} - \mathbf{d} + \mathbf{p}^{(n)} \|_2^2 \tag{33}
   \]

3. **Обновление \( \mathbf{p} \)**:

   \[
   \mathbf{p}^{(n+1)} = \mathbf{p}^{(n)} + \mathbf{x}^{(n+1)} - \mathbf{d}^{(n+1)} \tag{34}
   \]

#### Обновление Параметров

Параметры \( \boldsymbol{\mu} \) и \( \delta \) обновляются следующим образом:

\[
\boldsymbol{\mu}^{(n+1)} = \boldsymbol{\mu}^{(n)} + \delta^{(n)} (\mathbf{x}^{(n+1)} - \mathbf{d}^{(n+1)}) \tag{35}
\]

\[
\delta^{(n+1)} = \min(\delta^{(n)}, \delta_{\text{max}}) \tag{36}
\]

- \( \delta_{\text{max}} \) — максимальное значение параметра \( \delta \).

### Пошаговое Решение

#### Обновление \( \mathbf{x} \) (уравнение 32)

Это квадратичная задача без ограничений, решение которой дается выражением:

\[
\mathbf{x}^{(n+1)} = \left( (\mathbf{P} \times_3 \mathcal{A})^\top (\mathbf{P} \times_3 \mathcal{A}) + \delta^{(n)} \mathbf{I} \right)^{-1} \left( (\mathbf{P} \times_3 \mathcal{A})^\top \mathbf{Y} + \delta^{(n)} (\mathbf{d}^{(n)} - \mathbf{p}^{(n)}) \right)
\]

- \( \mathbf{I} \) — единичная матрица.
- Вычисление обратной матрицы может быть дорогостоящим для больших размеров, поэтому на практике могут использоваться численные методы.

#### Обновление \( \mathbf{d} \) (уравнение 33)

Это задача минимизации суммы \( \ell_1 \)-нормы и квадратичной функции. Решение осуществляется с помощью **итеративного алгоритма порогового сжатия** (Iterative Shrinkage-Thresholding Algorithm, ISTA):

\[
\mathbf{d}^{(n+1)} = \operatorname{Shrinkage}\left( \mathbf{x}^{(n+1)} + \mathbf{p}^{(n)}, \frac{\lambda}{\delta^{(n)}} \right)
\]

Где оператор сжатия (\( \operatorname{Shrinkage} \)) определяется как:

\[
\operatorname{Shrinkage}(v, \theta) = \begin{cases}
v - \theta, & \text{если } v > \theta \\
0, & \text{если } |v| \leq \theta \\
v + \theta, & \text{если } v < -\theta
\end{cases}
\]

Применяется поэлементно к вектору \( \mathbf{v} \).

#### Обновление \( \mathbf{p} \) (уравнение 34)

Простое обновление множителя Лагранжа:

\[
\mathbf{p}^{(n+1)} = \mathbf{p}^{(n)} + \mathbf{x}^{(n+1)} - \mathbf{d}^{(n+1)}
\]

### Итоговый Алгоритм

Алгоритм 3 описывает полную процедуру тензорного компрессивного измерения.

---

**Алгоритм 3: Тензорное Компрессивное Измерение**

**Входные данные**:

- \( \mathcal{A} \) — тензор словаря.
- \( \mathbf{P} \) — оператор выбора датчиков.
- \( \mathbf{Y} \) — измерения с датчиков.
- \( \text{max\_iter} \) — максимальное число итераций.
- \( \epsilon \) — малое число для порогового сжатия.
- \( \lambda \) — параметр регуляризации.
- \( \delta^{(0)} \) — начальное значение параметра \( \delta \).
- \( \delta_{\text{max}} \) — максимальное значение \( \delta \).

**Выходные данные**:

- \( \hat{\mathbf{x}} \) — восстановленный вектор весов.

**Шаги алгоритма**:

1. **Инициализация**:

   - \( I, J, W \leftarrow \text{size}(\mathcal{A}) \) — размеры тензора \( \mathcal{A} \).
   - \( \mathbf{x}^{(0)} = \mathbf{0} \), \( \mathbf{d}^{(0)} = \mathbf{0} \), \( \mathbf{p}^{(0)} = \mathbf{0} \).
   - Обновляем тензор: \( \mathcal{A} \leftarrow \mathbf{P} \times_3 \mathcal{A} \).

2. **Основной цикл**: для \( n = 1 \) до \( \text{max\_iter} \):

   a. **Обновление \( \mathbf{x} \)**:

      \[
      \mathbf{x}^{(n)} \leftarrow \left( \mathcal{A}^\top \cdot \mathcal{A} + \delta^{(n-1)} \mathbf{I} \right)^{-1} \left( \mathcal{A}^\top \cdot \mathbf{Y} + \delta^{(n-1)} \left( \mathbf{d}^{(n-1)} - \mathbf{p}^{(n-1)} \right) \right)
      \]

   b. **Промежуточное значение \( \hat{\mathbf{x}} \)**:

      \[
      \hat{\mathbf{x}} \leftarrow \lambda \mathbf{x}^{(n)} + (1 - \lambda) \mathbf{d}^{(n-1)}
      \]

   c. **Обновление \( \mathbf{d} \) через пороговое сжатие**:

      \[
      \mathbf{d}^{(n)} \leftarrow \operatorname{Shrinkage}\left( \hat{\mathbf{x}} + \mathbf{p}^{(n-1)}, \frac{\epsilon}{\delta^{(n-1)}} \right)
      \]

   d. **Обновление \( \mathbf{p} \)**:

      \[
      \mathbf{p}^{(n)} \leftarrow \mathbf{p}^{(n-1)} + \hat{\mathbf{x}} - \mathbf{d}^{(n)}
      \]

   e. **Обновление \( \delta \)**:

      \[
      \delta^{(n)} \leftarrow \min(\delta^{(n-1)}, \delta_{\text{max}})
      \]

3. **Выход**: Возвращаем \( \hat{\mathbf{x}} \).

---

## Пояснение Новых Терминов и Концепций

### Компрессивное Измерение (Compressive Sensing)

- **Основная идея**: Если сигнал является разреженным в некотором базисе, его можно восстановить из малого числа несвязанных измерений.

### \( \ell_0 \)-норма и \( \ell_1 \)-норма

- **\( \ell_0 \)-норма**: Количество ненулевых элементов вектора.
- **\( \ell_1 \)-норма**: Сумма абсолютных значений элементов вектора.

**Примечание**: Минимизация \( \ell_0 \)-нормы является NP-трудной задачей. Поэтому на практике используется минимизация \( \ell_1 \)-нормы, которая является выпуклой и может быть решена эффективно.

### Свойство Ограниченной Изометрии (RIP)

- **Суть**: Гарантирует, что разреженные сигналы сохраняют свою геометрию при отображении в пространство измерений.
- **Значимость**: Выполнение RIP позволяет использовать методы минимизации \( \ell_1 \)-нормы для точного восстановления разреженных сигналов.

### Метод ADMM

- **Alternating Direction Method of Multipliers** — итеративный алгоритм для решения задач оптимизации с ограничениями.
- **Преимущества**: Разбивает сложную задачу на более простые подзадачи, которые легче решить.
- **Применение**: Широко используется в задачах, связанных с разреженными представлениями и оптимизацией с \( \ell_1 \)-регуляризацией.

### Итеративный Алгоритм Порогового Сжатия (ISTA)

- **Цель**: Решение задач минимизации, включающих \( \ell_1 \)-норму.
- **Оператор сжатия**: Применяется поэлементно и обеспечивает разреженность решения.

### Тензорное Произведение и Операции

- **\( \times_3 \)**: Оператор произведения тензора на матрицу по третьему измерению.
- **\( \mathcal{A} \times_{(3)} \mathbf{x} \)**: Означает, что мы умножаем тензор \( \mathcal{A} \) на вектор \( \mathbf{x} \) по третьему измерению.

### Норма Фробениуса

- **Определение**: Квадратный корень из суммы квадратов всех элементов матрицы или тензора.
- **Обозначение**: \( \| \cdot \|_F \).

## Заключение

Предложенный метод тензорного компрессивного измерения позволяет эффективно восстанавливать глобальное поле динамической системы на основе разреженных измерений. Использование ADMM обеспечивает решение невыпуклых задач оптимизации, связанных с разреженными представлениями в тензорных пространствах.

- **Преимущества метода**:

  - Учитывает тензорную природу данных.
  - Позволяет использовать меньшее количество датчиков для точного восстановления поля.
  - Эффективен в вычислительном отношении благодаря разбиению задачи на подзадачи.

- **Практические приложения**:

  - Мониторинг сложных динамических систем.
  - Обработка изображений и сигналов высокой размерности.
  - Решение задач в областях, где данные естественным образом представлены в виде тензоров.

---

## Дополнительные Объяснения

В данной секции мы подробно рассмотрим следующие понятия, упомянутые в вашем вопросе:

1. **Теорема выборки Найквиста-Шеннона**
2. **Произведение по третьему измерению**
3. **Свойство Ограниченной Изометрии (Restricted Isometry Property, RIP)**

### 1. Теорема Выборки Найквиста-Шеннона

#### Что такое Теорема Найквиста-Шеннона?

**Теорема выборки Найквиста-Шеннона** — фундаментальный результат в теории информации и обработке сигналов, который устанавливает условия для точного восстановления непрерывного сигнала из его дискретных выборок.

#### Формулировка Теоремы

Если сигнал \( x(t) \) ограничен по частоте, то есть его спектр содержит частоты только до некоторой максимальной частоты \( f_{\text{max}} \), то он может быть точно восстановлен из своих дискретных выборок, если частота выборки \( f_s \) удовлетворяет условию:

\[
f_s \geq 2 f_{\text{max}}
\]

Это неравенство называется **частотой Найквиста**. Оно гласит, что частота дискретизации должна быть не менее удвоенной максимальной частоты сигнала.

#### Интуитивное Объяснение

- **Ограниченный по частоте сигнал**: Сигнал, у которого нет компонентов выше определенной частоты.
- **Дискретизация**: Процесс преобразования непрерывного сигнала в последовательность его значений в определенные моменты времени.
- **Точное восстановление**: Возможность восстановить исходный непрерывный сигнал без искажений из дискретных выборок.

#### Значение Теоремы

- **Предотвращение эффекта наложения спектров (алиасинга)**: Если частота дискретизации ниже, чем частота Найквиста, высокочастотные компоненты сигнала будут искажены и наложены на низкочастотные компоненты, что приведет к потере информации.
- **Практическое применение**: Теорема используется в цифровой обработке сигналов, аудио и видеотехнологиях, телекоммуникациях и других областях.

#### Связь с Компрессивным Измерением

В компрессивном измерении теорема Найквиста-Шеннона служит отправной точкой. Однако компрессивное измерение позволяет восстанавливать сигналы из меньшего числа измерений, чем требуется по теореме Найквиста, при условии, что сигнал является разреженным в некотором базисе.

### 2. Произведение по Третьему Измерению

#### Тензорное Произведение

В тензорной алгебре операция произведения тензора на матрицу или вектор по определенному измерению позволяет преобразовывать и манипулировать многомерными данными.

#### Определение Операции

- Пусть \( \mathcal{A} \in \mathbb{R}^{I \times J \times K} \) — тензор третьего порядка.
- Пусть \( \mathbf{x} \in \mathbb{R}^{K} \) — вектор.
- **Произведение тензора \( \mathcal{A} \) на вектор \( \mathbf{x} \) по третьему измерению** обозначается как \( \mathcal{A} \times_{(3)} \mathbf{x} \) и определяется следующим образом:

\[
(\mathcal{A} \times_{(3)} \mathbf{x})_{ij} = \sum_{k=1}^{K} \mathcal{A}_{ijk} x_k
\]

- Результатом является матрица размера \( I \times J \).

#### Визуализация

- **Третье измерение** в тензоре можно представить как глубину или слои (например, страницы книги).
- **Произведение по третьему измерению** сворачивает тензор по этому измерению, комбинируя информацию из всех слоев с помощью вектора \( \mathbf{x} \).

#### Применение в Контексте

- В нашей задаче \( \mathcal{A} \) — тензор словаря, содержащий базисные функции или моды системы.
- Вектор \( \mathbf{x} \) — весовые коэффициенты, определяющие вклад каждой моды.
- Операция \( \mathcal{A} \times_{(3)} \mathbf{x} \) позволяет восстановить поле \( \mathbf{X} \) из комбинации мод с соответствующими весами.

#### Пример

Предположим, что \( \mathcal{A} \) имеет размеры \( 2 \times 2 \times 3 \), а \( \mathbf{x} = [x_1, x_2, x_3]^\top \).

Тогда для элемента \( (i, j) \) матрицы результата:

\[
(\mathcal{A} \times_{(3)} \mathbf{x})_{ij} = \mathcal{A}_{ij1} x_1 + \mathcal{A}_{ij2} x_2 + \mathcal{A}_{ij3} x_3
\]

### 3. Свойство Ограниченной Изометрии (Restricted Isometry Property, RIP)

#### Что такое RIP?

**Свойство Ограниченной Изометрии** — ключевое понятие в компрессивном измерении, которое обеспечивает условия для точного восстановления разреженных сигналов из сжатыx измерений.

#### Математическое Определение

Оператор измерений \( \Phi \) удовлетворяет RIP порядка \( s \) с константой \( \delta_s \), если для всех \( s \)-разреженных векторов \( \mathbf{x} \) выполняется:

\[
(1 - \delta_s) \| \mathbf{x} \|_2^2 \leq \| \Phi \mathbf{x} \|_2^2 \leq (1 + \delta_s) \| \mathbf{x} \|_2^2
\]

- \( \delta_s \in (0, 1) \) — константа RIP.
- \( s \)-разреженный вектор — вектор, у которого не более \( s \) ненулевых элементов.

#### Интуитивное Объяснение

- **Изометрия** означает сохранение расстояний.
- **Ограниченная изометрия** подразумевает, что оператор измерений \( \Phi \) почти сохраняет евклидовы нормы всех \( s \)-разреженных векторов.
- То есть, разреженные векторы не "сжимаются" и не "растягиваются" слишком сильно при преобразовании оператором \( \Phi \).

#### Значение в Компрессивном Измерении

- Если оператор измерений удовлетворяет RIP с малой константой \( \delta_s \), то можно гарантировать точное восстановление разреженных сигналов с помощью методов минимизации \( \ell_1 \)-нормы.
- RIP обеспечивает теоретическую основу для того, почему компрессивное измерение работает.

#### Применение в Контексте

- В нашем случае оператор измерений представлен как \( \mathbf{P} \times_3 \mathcal{A} \), где \( \mathbf{P} \) — оператор выбора датчиков.
- Необходимо, чтобы этот оператор удовлетворял RIP для того, чтобы гарантировать точное восстановление вектора весов \( \mathbf{x} \), а следовательно, и поля \( \mathbf{X} \).

#### Условия Выполнения RIP

- **Размерность**: Необходимое количество измерений \( M \) должно быть достаточно большим по сравнению с уровнем разреженности \( s \).
- Обычно требуется, чтобы \( M \geq C s \log \left( \frac{N}{s} \right) \), где \( C \) — некоторая константа, \( N \) — размерность вектора \( \mathbf{x} \).

#### Связь с Матрицами Случайных Измерений

- Многие случайные матрицы, такие как матрицы с элементами, взятыми из нормального распределения, удовлетворяют RIP с высокой вероятностью при достаточном числе измерений.
- Однако в нашей задаче оператор измерений определяется выбором датчиков, и необходимо убедиться, что выбранные позиции датчиков обеспечивают выполнение RIP.

#### Практическое Значение

- **Гарантии Восстановления**: Выполнение RIP позволяет использовать алгоритмы минимизации \( \ell_1 \)-нормы для восстановления разреженных сигналов.
- **Оптимизация Размещения Датчиков**: При выборе оптимальных позиций для датчиков необходимо учитывать выполнение RIP, чтобы обеспечить точность восстановления.

## Заключение

Понимание перечисленных концепций является ключевым для эффективного применения методов компрессивного измерения и оптимального размещения датчиков в задачах восстановления полей высокоразмерных динамических систем.

- **Теорема Найквиста-Шеннона** устанавливает фундаментальные ограничения на дискретизацию сигналов и служит основой для дальнейших методов в цифровой обработке сигналов.
- **Произведение по третьему измерению** — важная операция в тензорной алгебре, позволяющая манипулировать многомерными данными и строить модели систем на основе тензорных представлений.
- **Свойство Ограниченной Изометрии** обеспечивает теоретические гарантии для точного восстановления разреженных сигналов из сжатых измерений и является критическим при разработке эффективных алгоритмов компрессивного измерения.

---

## Ссылки

[48] Candès, E. J., & Wakin, M. B. (2008). An introduction to compressive sampling. IEEE signal processing magazine, 25(2), 21-30.

[49] Donoho, D. L. (2006). Compressed sensing. IEEE Transactions on information theory, 52(4), 1289-1306.
